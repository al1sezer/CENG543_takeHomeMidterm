{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "407b24e7",
      "metadata": {},
      "source": [
        "# Question 2: Neural Machine Translation with Attention Mechanisms"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bffb29a",
      "metadata": {
        "id": "2bffb29a"
      },
      "source": [
        "## Imports and Setup\n",
        "Imports necessary libraries (PyTorch, SpaCy, datasets) and sets random seeds for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a2ad2c6-d93a-4f27-87d9-9a48ec5540e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5a2ad2c6-d93a-4f27-87d9-9a48ec5540e0",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "b6570adc-cecb-4bd2-ab42-395ce1d935c2"
      },
      "outputs": [],
      "source": [
        "# Import core libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# Load Hugging Face datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load spaCy for tokenization\n",
        "import spacy\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Configure device (GPU/CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c334032",
      "metadata": {},
      "source": [
        "## Dataset Loading and Tokenization\n",
        "Loads the Multi30k German-English dataset from Hugging Face and applies SpaCy tokenization to both source and target languages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09b9188b-b92c-4d09-84cd-834580e18da6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a3004be1f35c40edb8b1c58dd73d093b",
            "da56b3abef4145309af827c337358c16",
            "9f9a86f8a3c24237814d249777327726",
            "122df9973ad94b788c40be2ee17507ee",
            "3eb2a3e890d8409d8053cf6d00a13b67",
            "aca8362e1ae24c1796f1b387eacd714f",
            "5039750a58474787b399e781ba8627ee",
            "cb0663ae002544f59702e8498f2e34a5",
            "a091c10fa42346d7b59bc72676d5bb7d",
            "2357faf8224d441d9965e1f30a0d4e41",
            "fd21256649d049fe9aabffcadf7a9473",
            "a1658274fcb64747bf7bf12a686ce0ee",
            "a8562c8af9444aa091ea083c893205c3",
            "e2253d46aadd46588fe7c7005e0ba3b9",
            "4c04de4e32294f66884a11df95fc30bf",
            "544123e4bab845eb8740723748936de0",
            "147a36f534134f24a986a725bda8bd7c",
            "0a1040eb409a4cc8af8aa7d23e72570c",
            "be83520a9e1c4df7bb33397827b97a5e",
            "689584c0263e4ca28a99cd78f66cb0ba",
            "70bc34df64b3480285bd61a95c8bcf3d",
            "5c5afd74794d4e43821660a0299f17dc",
            "38ec759f3b2e471487a8e8654bff9e2d",
            "5d43a49d9eb349f9856d6a9d8edf95e5",
            "80dd0600bba946edbf3a4d32a1047bd0",
            "66cdf8dd440b4e54a5b7dd2166a6dee5",
            "0596fd1400e7494a980f6276305d0b23",
            "bea940495ee7419a98c1357dfdc1dee9",
            "53e5062051cb435481f8a81da1a484ff",
            "64c0a13198c943308f5065722ea3ff08",
            "8875b0be938e4a1fab49ecc38cfbc793",
            "a0b117b83d264bc8a1aa36576e9cbdc2",
            "453540ce326746b5a9e33e3069f9b364"
          ]
        },
        "collapsed": true,
        "id": "09b9188b-b92c-4d09-84cd-834580e18da6",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "04f0e2b0-9653-4172-e4a0-afc12e941332"
      },
      "outputs": [],
      "source": [
        "# Load spaCy language models\n",
        "try:\n",
        "    spacy_de = spacy.load('de_core_news_sm')  # Source: German\n",
        "    spacy_en = spacy.load('en_core_web_sm')  # Target: English\n",
        "    print(\"  spaCy language models loaded successfully\")\n",
        "except IOError:\n",
        "    print(\"\\n--- ERROR ---\")\n",
        "    print(\"spaCy models not found. Please run installation commands.\")\n",
        "\n",
        "# Load Multi30k dataset from Hugging Face\n",
        "DATASET_ID = \"bentrevett/multi30k\"\n",
        "print(f\"\\n'{DATASET_ID}' dataset loading from Hugging Face Hub...\")\n",
        "\n",
        "try:\n",
        "    # Load dataset splits\n",
        "    dataset = load_dataset(DATASET_ID)\n",
        "\n",
        "    # Rename validation split to 'valid'\n",
        "    dataset['valid'] = dataset.pop('validation')\n",
        "\n",
        "    print(\"Dataset loaded:\")\n",
        "    print(dataset)\n",
        "\n",
        "    print(\"\\nSample data (train[0]):\")\n",
        "    print(dataset['train'][0])\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nError loading dataset: {e}\")\n",
        "    print(\"Will try Method 2 (Pandas).\")\n",
        "    dataset = None\n",
        "\n",
        "# Define tokenization function\n",
        "def tokenize_example(example):\n",
        "    \"\"\"Tokenize source and target sequences.\"\"\"\n",
        "    src_tokens = [tok.text for tok in spacy_de.tokenizer(example['de'].lower())]\n",
        "    trg_tokens = [tok.text for tok in spacy_en.tokenizer(example['en'].lower())]\n",
        "    return {'src_tokens': src_tokens, 'trg_tokens': trg_tokens}\n",
        "\n",
        "if dataset:\n",
        "    print(\"\\nTokenizer function defined. Applying to dataset...\")\n",
        "    tokenized_datasets = dataset.map(tokenize_example, batched=False)\n",
        "\n",
        "    print(\"\\nTokenized dataset:\")\n",
        "    print(tokenized_datasets)\n",
        "    print(\"\\nTokenized example (train[0]):\")\n",
        "    print(tokenized_datasets['train'][0])\n",
        "else:\n",
        "    print(\"\\nDataset loading failed. Skipping tokenization.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30e09367",
      "metadata": {},
      "source": [
        "## Vocabulary Building\n",
        "Creates source (German) and target (English) vocabularies with special tokens (UNK, PAD, SOS, EOS) and minimum frequency filtering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9188699d-3899-4c4a-9bae-cb78b12c4a86",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9188699d-3899-4c4a-9bae-cb78b12c4a86",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "5f75ec22-c62b-497b-e45d-3d8de86f6644"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Define special tokens\n",
        "UNK_TOKEN = '<unk>'  # Unknown word\n",
        "PAD_TOKEN = '<pad>'  # Padding token\n",
        "SOS_TOKEN = '<sos>'  # Start of sentence\n",
        "EOS_TOKEN = '<eos>'  # End of sentence\n",
        "special_tokens = [UNK_TOKEN, PAD_TOKEN, SOS_TOKEN, EOS_TOKEN]\n",
        "MIN_FREQ = 2  # Minimum frequency threshold\n",
        "\n",
        "# Build source (German) vocabulary\n",
        "src_counter = Counter()\n",
        "for example in tokenized_datasets['train']:\n",
        "    src_counter.update(example['src_tokens'])\n",
        "\n",
        "src_itos = list(special_tokens)\n",
        "src_itos.extend([token for token, freq in src_counter.items() if freq >= MIN_FREQ])\n",
        "src_stoi = {token: i for i, token in enumerate(src_itos)}\n",
        "UNK_IDX = src_stoi[UNK_TOKEN]\n",
        "\n",
        "# Build target (English) vocabulary\n",
        "trg_counter = Counter()\n",
        "for example in tokenized_datasets['train']:\n",
        "    trg_counter.update(example['trg_tokens'])\n",
        "\n",
        "trg_itos = list(special_tokens)\n",
        "trg_itos.extend([token for token, freq in trg_counter.items() if freq >= MIN_FREQ])\n",
        "trg_stoi = {token: i for i, token in enumerate(trg_itos)}\n",
        "TRG_UNK_IDX = trg_stoi[UNK_TOKEN]\n",
        "\n",
        "print(f\"  Vocabularies built: DE={len(src_stoi)}, EN={len(trg_stoi)}\")\n",
        "\n",
        "\n",
        "# Store important indices\n",
        "PAD_IDX = src_stoi[PAD_TOKEN]\n",
        "SOS_IDX = src_stoi[SOS_TOKEN]\n",
        "EOS_IDX = src_stoi[EOS_TOKEN]\n",
        "\n",
        "print(f\"\\n  Special tokens: UNK(DE)={UNK_IDX}, PAD={PAD_IDX}, SOS={SOS_IDX}\")\n",
        "# Assign vocabularies for later use\n",
        "src_vocab = src_stoi\n",
        "trg_vocab = trg_stoi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02792001",
      "metadata": {},
      "source": [
        "## DataLoader Setup\n",
        "Defines custom collate function for variable-length sequences and creates train/valid/test DataLoaders with padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "934405b9-ba19-4afb-8cbd-b9af24230c99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "934405b9-ba19-4afb-8cbd-b9af24230c99",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "72a0ff0b-c609-4a61-d2ad-b6818f827338"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    \"\"\"Custom collate function for variable-length sequences.\"\"\"\n",
        "    src_batch, trg_batch = [], []\n",
        "\n",
        "    for example in batch:\n",
        "        # Extract token lists\n",
        "        src_tokens = example['src_tokens']\n",
        "        trg_tokens = example['trg_tokens']\n",
        "\n",
        "        # Convert tokens to indices\n",
        "        src_indices = [src_vocab.get(token, UNK_IDX) for token in src_tokens]\n",
        "        trg_indices = [trg_vocab.get(token, TRG_UNK_IDX) for token in trg_tokens]\n",
        "\n",
        "        # Add SOS/EOS tokens\n",
        "        src_processed = torch.tensor([SOS_IDX] + src_indices + [EOS_IDX], dtype=torch.long)\n",
        "        trg_processed = torch.tensor([SOS_IDX] + trg_indices + [EOS_IDX], dtype=torch.long)\n",
        "\n",
        "        # Move to device\n",
        "        src_batch.append(src_processed.to(device))\n",
        "        trg_batch.append(trg_processed.to(device))\n",
        "\n",
        "    # Pad sequences to [seq_len, batch_size]\n",
        "    src_padded = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    trg_padded = pad_sequence(trg_batch, padding_value=PAD_IDX)\n",
        "\n",
        "    return src_padded, trg_padded\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataloader = DataLoader(tokenized_datasets['train'],\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True,\n",
        "                              collate_fn=collate_fn)\n",
        "\n",
        "valid_dataloader = DataLoader(tokenized_datasets['valid'],\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=False,\n",
        "                              collate_fn=collate_fn)\n",
        "\n",
        "test_dataloader = DataLoader(tokenized_datasets['test'],\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False,\n",
        "                             collate_fn=collate_fn)\n",
        "\n",
        "print(f\"  DataLoaders created (batch_size={BATCH_SIZE})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab781899",
      "metadata": {},
      "source": [
        "## Encoder Architecture\n",
        "Implements bidirectional GRU encoder with embedding layer and dropout for the shared backbone across all attention models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0abaeaa8-636c-48f6-87c3-a23b6c7514b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0abaeaa8-636c-48f6-87c3-a23b6c7514b0",
        "outputId": "366da2a9-0d41-4c27-dfb4-2f645b6ba276"
      },
      "outputs": [],
      "source": [
        "# Model hyperparameters\n",
        "INPUT_DIM = len(src_vocab)    # Source vocabulary size\n",
        "OUTPUT_DIM = len(trg_vocab)   # Target vocabulary size\n",
        "ENC_EMB_DIM = 256             # Encoder embedding dimension\n",
        "DEC_EMB_DIM = 256             # Decoder embedding dimension\n",
        "HID_DIM = 256                 # RNN hidden dimension\n",
        "N_LAYERS = 2                  # Number of RNN layers\n",
        "ENC_DROPOUT = 0.5             # Encoder dropout rate\n",
        "DEC_DROPOUT = 0.5             # Decoder dropout rate\n",
        "\n",
        "# Calculated dimensions for attention\n",
        "ENC_HID_DIM_CALC = HID_DIM * 2  # Bidirectional encoder output\n",
        "DEC_HID_DIM_CALC = HID_DIM      # Decoder hidden dimension\n",
        "ATTN_DIM = 256                  # Attention dimension\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        # Embedding layer (trainable from scratch)\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx = PAD_IDX)\n",
        "\n",
        "        # Bidirectional GRU\n",
        "        self.rnn = nn.GRU(\n",
        "            input_size=emb_dim,\n",
        "            hidden_size=hid_dim,\n",
        "            num_layers=n_layers,\n",
        "            dropout = dropout if n_layers > 1 else 0,\n",
        "            bidirectional = True,\n",
        "            batch_first = False\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src = [src_len, batch_size]\n",
        "\n",
        "        # Pass through embedding\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "        # Pass through RNN\n",
        "        # outputs = [src_len, batch_size, hid_dim * 2]\n",
        "        # hidden  = [n_layers * 2, batch_size, hid_dim]\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "\n",
        "        return outputs, hidden\n",
        "\n",
        "print(\"  Encoder defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c430c88",
      "metadata": {},
      "source": [
        "## Bahdanau (Additive) Attention\n",
        "Implements Bahdanau attention mechanism using additive scoring with learnable weight matrices and tanh activation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "185ac375-f257-449c-8cf2-85f80f63b6eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "185ac375-f257-449c-8cf2-85f80f63b6eb",
        "outputId": "7c806b84-6755-4cc2-a67f-da2f3b95c093"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim, attn_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # Linear layers for Bahdanau attention\n",
        "        self.attn_enc = nn.Linear(enc_hid_dim, attn_dim)  # Project encoder outputs\n",
        "        self.attn_dec = nn.Linear(dec_hid_dim, attn_dim)  # Project decoder hidden\n",
        "        self.v = nn.Linear(attn_dim, 1, bias = False)     # Energy to scalar\n",
        "\n",
        "    def forward(self, decoder_hidden, encoder_outputs):\n",
        "\n",
        "        # decoder_hidden  = [batch_size, dec_hid_dim]\n",
        "        # encoder_outputs = [src_len, batch_size, enc_hid_dim]\n",
        "\n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        # Reshape for alignment\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)  # [batch, src_len, enc_hid]\n",
        "        decoder_hidden = decoder_hidden.unsqueeze(1)         # [batch, 1, dec_hid]\n",
        "\n",
        "        # Apply Bahdanau formula\n",
        "        enc_proj = self.attn_enc(encoder_outputs)  # [batch, src_len, attn_dim]\n",
        "        dec_proj = self.attn_dec(decoder_hidden)   # [batch, 1, attn_dim]\n",
        "\n",
        "        # Combine with tanh activation\n",
        "        combined_energy = torch.tanh(enc_proj + dec_proj)  # [batch, src_len, attn_dim]\n",
        "\n",
        "        # Reduce to scalar scores\n",
        "        energy = self.v(combined_energy).squeeze(2)  # [batch, src_len]\n",
        "\n",
        "        # Apply softmax to get attention weights\n",
        "        return F.softmax(energy, dim=1)\n",
        "\n",
        "print(\"  Attention (Bahdanau) defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d924bcf",
      "metadata": {},
      "source": [
        "## Decoder with Attention\n",
        "Implements GRU decoder that uses attention-weighted context vectors combined with embeddings for prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c488041-3113-4068-9dcc-ae45fb94a309",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8c488041-3113-4068-9dcc-ae45fb94a309",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "901406dc-d604-4e31-f019-b5d79d04b4a5"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim,\n",
        "                 dropout, n_layers, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = dec_hid_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        # Attention mechanism\n",
        "        self.attention = attention\n",
        "\n",
        "        # Embedding layer for target language\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx = PAD_IDX)\n",
        "\n",
        "        # Decoder RNN (input = embedding + context)\n",
        "        self.rnn = nn.GRU(\n",
        "            input_size = emb_dim + enc_hid_dim,\n",
        "            hidden_size = dec_hid_dim,\n",
        "            num_layers = n_layers,\n",
        "            dropout = dropout if n_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # Output layer (combines RNN output + context + embedding)\n",
        "        self.fc_out = nn.Linear(\n",
        "            in_features = emb_dim + enc_hid_dim + dec_hid_dim,\n",
        "            out_features = output_dim\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_token, decoder_hidden, encoder_outputs):\n",
        "\n",
        "        # input_token     = [batch_size]\n",
        "        # decoder_hidden  = [n_layers, batch_size, dec_hid_dim]\n",
        "        # encoder_outputs = [src_len, batch_size, enc_hid_dim]\n",
        "\n",
        "        # Reshape input token to [1, batch_size]\n",
        "        input_token = input_token.unsqueeze(0)\n",
        "\n",
        "        # Embedding\n",
        "        embedded = self.dropout(self.embedding(input_token))  # [1, batch, emb_dim]\n",
        "\n",
        "        # Get attention weights\n",
        "        attn_weights = self.attention(decoder_hidden[-1], encoder_outputs)\n",
        "\n",
        "        # Calculate weighted context\n",
        "        attn_weights_unsqueezed = attn_weights.unsqueeze(1)  # [batch, 1, src_len]\n",
        "        encoder_outputs_permuted = encoder_outputs.permute(1, 0, 2)  # [batch, src_len, enc_hid]\n",
        "\n",
        "        # Batch matrix multiply\n",
        "        weighted_context = torch.bmm(attn_weights_unsqueezed, encoder_outputs_permuted)\n",
        "        weighted_context = weighted_context.permute(1, 0, 2)  # [1, batch, enc_hid]\n",
        "\n",
        "        # Concatenate embedding and context\n",
        "        rnn_input = torch.cat((embedded, weighted_context), dim=2)\n",
        "\n",
        "        # Run RNN\n",
        "        output, hidden = self.rnn(rnn_input, decoder_hidden)\n",
        "\n",
        "        # Prepare for prediction\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted_context = weighted_context.squeeze(0)\n",
        "\n",
        "        # Combine all for prediction\n",
        "        combined_for_pred = torch.cat((output, weighted_context, embedded), dim=1)\n",
        "\n",
        "        # Final prediction\n",
        "        prediction = self.fc_out(combined_for_pred)\n",
        "\n",
        "        return prediction, hidden,attn_weights\n",
        "\n",
        "print(\"  Decoder defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "416c9787",
      "metadata": {},
      "source": [
        "## Seq2Seq Model with Bridge\n",
        "Combines encoder and decoder with a bridge layer to transform bidirectional encoder hidden states to unidirectional decoder hidden states."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fda730c-cdfb-423a-9497-280906aed6da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9fda730c-cdfb-423a-9497-280906aed6da",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "c1d692b2-f954-4e53-8f98-0cb57c475a64"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device, pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "        # Bridge layer: bidirectional encoder -> unidirectional decoder\n",
        "        self.fc_hidden = nn.Linear(encoder.hid_dim * 2, decoder.hid_dim)\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "\n",
        "        # src = [src_len, batch_size]\n",
        "        # trg = [trg_len, batch_size]\n",
        "\n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        # Store all decoder predictions\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        # Step 1: Encode source sequence\n",
        "        encoder_outputs, encoder_hidden = self.encoder(src)\n",
        "\n",
        "        # Step 2: Bridge - transform encoder hidden to decoder hidden\n",
        "        encoder_hidden = encoder_hidden.view(self.encoder.n_layers, 2, batch_size, self.encoder.hid_dim)\n",
        "        encoder_hidden_cat = torch.cat((encoder_hidden[:, 0, :, :], encoder_hidden[:, 1, :, :]), dim=2)\n",
        "        decoder_hidden = torch.tanh(self.fc_hidden(encoder_hidden_cat))\n",
        "\n",
        "        # Step 3: Decode with teacher forcing\n",
        "        input_token = trg[0, :] \n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "\n",
        "            # Decoder forward pass\n",
        "            prediction, decoder_hidden, _ = self.decoder(\n",
        "                input_token,\n",
        "                decoder_hidden,\n",
        "                encoder_outputs\n",
        "            )\n",
        "\n",
        "            # Store prediction\n",
        "            outputs[t] = prediction\n",
        "\n",
        "            # Teacher forcing: decide whether to use ground truth or prediction\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = prediction.argmax(1)  # Get predicted token\n",
        "\n",
        "            input_token = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs\n",
        "\n",
        "print(\"  Seq2Seq model defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8defaed7",
      "metadata": {},
      "source": [
        "## Training and Evaluation Functions\n",
        "Defines train/evaluate functions with gradient clipping, loss calculation, and helper utilities for epoch timing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8a5762a-c671-42a7-b290-5f15822e7e07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "e8a5762a-c671-42a7-b290-5f15822e7e07",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "8fe59f86-27f3-46d8-bc6a-5f85328e7083"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Helper function to count trainable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# Training function\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train()  # Enable dropout\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i, (src, trg) in enumerate(iterator):\n",
        "        # src = [src_len, B], trg = [trg_len, B]\n",
        "\n",
        "        optimizer.zero_grad()  # Reset gradients\n",
        "\n",
        "        # Forward pass with teacher forcing\n",
        "        output = model(src, trg, teacher_forcing_ratio = 0.5)\n",
        "\n",
        "        # Calculate loss\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        # Reshape for CrossEntropyLoss: skip <sos> token\n",
        "        output_flat = output[1:].view(-1, output_dim)\n",
        "        trg_flat = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output_flat, trg_flat)\n",
        "\n",
        "        loss.backward()  # Backpropagation\n",
        "\n",
        "        # Gradient clipping to prevent exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()  # Disable dropout\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for i, (src, trg) in enumerate(iterator):\n",
        "\n",
        "            # No teacher forcing during evaluation\n",
        "            output = model(src, trg, teacher_forcing_ratio = 0.0)\n",
        "\n",
        "            # Calculate loss\n",
        "            output_dim = output.shape[-1]\n",
        "            output_flat = output[1:].view(-1, output_dim)\n",
        "            trg_flat = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output_flat, trg_flat)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "# Helper function for time formatting\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "print(\"\\n  Training functions defined. Model 1 ready for training.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a950d03",
      "metadata": {},
      "source": [
        "## Full Training Loop Function\n",
        "Reusable training loop function that handles epoch iteration, model saving, and loss/perplexity logging for all models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wWKKLTzCWNhR",
      "metadata": {
        "id": "wWKKLTzCWNhR"
      },
      "outputs": [],
      "source": [
        "def train_full_model(model, train_iterator, valid_iterator, optimizer, criterion,\n",
        "                     n_epochs, clip, model_save_path, model_name=\"Model\"):\n",
        "    \"\"\"\n",
        "    Common training loop for Seq2Seq models.\n",
        "    Saves the best model based on validation loss.\n",
        "    \"\"\"\n",
        "    best_valid_loss = float('inf')\n",
        "\n",
        "    print(f\"\\nTraining {model_name} for {n_epochs} epochs...\")\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Training step\n",
        "        train_loss = train(model, train_iterator, optimizer, criterion, clip)\n",
        "\n",
        "        # Validation step\n",
        "        valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "        end_time = time.time()\n",
        "\n",
        "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "        # Calculate perplexity\n",
        "        train_ppl = math.exp(train_loss)\n",
        "        valid_ppl = math.exp(valid_loss)\n",
        "\n",
        "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(f'\\t[{model_name}] Train Loss: {train_loss:.3f} | Train PPL: {train_ppl:7.3f}')\n",
        "        print(f'\\t[{model_name}] Valid Loss: {valid_loss:.3f} | Valid PPL: {valid_ppl:7.3f}')\n",
        "\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            torch.save(model.state_dict(), model_save_path)\n",
        "            print(f'\\t>>> Best {model_name} saved: {model_save_path}')\n",
        "\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    print(f\"\\n  {model_name} training completed\")\n",
        "    print(f\"Best model saved as '{model_save_path}'.\")\n",
        "    return best_valid_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2a02c8c",
      "metadata": {},
      "source": [
        "## Model 1 Training (Bahdanau)\n",
        "Initializes and trains Model 1 with Bahdanau (additive) attention mechanism using Adam optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UgTd6yyJWUEZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgTd6yyJWUEZ",
        "outputId": "48f3be80-7ec3-4999-d677-460d4fd975fa"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Initialize model components\n",
        "encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT).to(device)\n",
        "attention = Attention(ENC_HID_DIM_CALC, DEC_HID_DIM_CALC, ATTN_DIM).to(device)\n",
        "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM_CALC, DEC_HID_DIM_CALC,\n",
        "                  DEC_DROPOUT, N_LAYERS, attention).to(device)\n",
        "\n",
        "# Create Model 1: Bahdanau-Attention-GRU\n",
        "model = Seq2Seq(encoder, decoder, device, PAD_IDX).to(device)\n",
        "\n",
        "# Initialize weights for better convergence\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "print(f\"  Model 1 (Bahdanau-GRU) initialized: {count_parameters(model):,} parameters\")\n",
        "\n",
        "# Setup optimizer\n",
        "LEARNING_RATE = 0.001\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Setup loss function\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
        "print(f\"  Optimizer: Adam (LR={LEARNING_RATE}), Loss: CrossEntropyLoss\")\n",
        "# Training hyperparameters\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1  # Gradient clipping threshold\n",
        "MODEL_SAVE_PATH = 'model-1-bahdanau-gru.pt'\n",
        "\n",
        "_ = train_full_model(\n",
        "    model=model,\n",
        "    train_iterator=train_dataloader,\n",
        "    valid_iterator=valid_dataloader,\n",
        "    optimizer=optimizer,\n",
        "    criterion=criterion,\n",
        "    n_epochs=N_EPOCHS,\n",
        "    clip=CLIP,\n",
        "    model_save_path=MODEL_SAVE_PATH,\n",
        "    model_name=\"Model 1 (Bahdanau)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9510d8d1",
      "metadata": {},
      "source": [
        "## Luong (Multiplicative) Attention\n",
        "Implements Luong \"General\" attention mechanism using multiplicative scoring between decoder hidden and projected encoder outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f3d2279-6280-43e2-bc24-2133f59c9015",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f3d2279-6280-43e2-bc24-2133f59c9015",
        "outputId": "ccafa802-39b8-440e-a94b-1107e078a24c"
      },
      "outputs": [],
      "source": [
        "class AttentionLuong(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # Luong \"General\" scoring: dec.T * (W * enc)\n",
        "        # Project encoder outputs to decoder hidden dimension\n",
        "        self.attn_in = nn.Linear(enc_hid_dim, dec_hid_dim)\n",
        "\n",
        "    def forward(self, decoder_hidden, encoder_outputs):\n",
        "\n",
        "        # decoder_hidden  = [batch_size, dec_hid_dim]\n",
        "        # encoder_outputs = [src_len, batch_size, enc_hid_dim]\n",
        "\n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        # Step 1: Project encoder outputs (W * enc)\n",
        "        encoder_proj = self.attn_in(encoder_outputs)  # [src_len, B, dec_hid_dim]\n",
        "\n",
        "        # Step 2: Prepare for batch matrix multiplication\n",
        "        decoder_hidden_unsqueezed = decoder_hidden.unsqueeze(1)  # [B, 1, H]\n",
        "        encoder_proj_permuted = encoder_proj.permute(1, 0, 2)    # [B, S, H]\n",
        "        encoder_proj_t = encoder_proj_permuted.permute(0, 2, 1)  # [B, H, S]\n",
        "\n",
        "        # Step 3: Multiplicative scoring\n",
        "        # [B, 1, H] @ [B, H, S] -> [B, 1, S]\n",
        "        energy_unsqueezed = torch.bmm(decoder_hidden_unsqueezed, encoder_proj_t)\n",
        "        energy = energy_unsqueezed.squeeze(1)  # [B, S]\n",
        "\n",
        "        # Step 4: Apply softmax\n",
        "        return F.softmax(energy, dim=1)\n",
        "\n",
        "print(\"  Attention (Luong) defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ce8a04d",
      "metadata": {},
      "source": [
        "## Model 2 Training (Luong)\n",
        "Initializes and trains Model 2 with Luong (multiplicative) attention mechanism."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74694807",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "74694807",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "cf7b36eb-29b8-4521-854f-67164e100772"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"=\"*70)\n",
        "print(\"MODEL 2 (LUONG)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "\n",
        "\n",
        "# Create Model 2 - Luong-GRU\n",
        "encoder_2 = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT).to(device)\n",
        "attention_2 = AttentionLuong(ENC_HID_DIM_CALC, DEC_HID_DIM_CALC).to(device)\n",
        "decoder_2 = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM_CALC, DEC_HID_DIM_CALC,\n",
        "                    DEC_DROPOUT, N_LAYERS, attention_2).to(device)\n",
        "\n",
        "model_2 = Seq2Seq(encoder_2, decoder_2, device, PAD_IDX).to(device)\n",
        "model_2.apply(init_weights)\n",
        "\n",
        "print(f\"  Model 2 (Luong-GRU) reinitialized: {count_parameters(model_2):,} parameters\")\n",
        "\n",
        "# Setup optimizer\n",
        "optimizer_2 = optim.Adam(model_2.parameters(), lr=LEARNING_RATE)\n",
        "print(f\"  Model 2 Optimizer: Adam (LR={LEARNING_RATE})\")\n",
        "# Training configuration\n",
        "MODEL_SAVE_PATH_2 = 'model-2-luong-gru.pt'\n",
        "\n",
        "best_valid_loss_2 = float('inf')\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"Model 2 (Luong-GRU)  - Training for {N_EPOCHS} epochs...\")\n",
        "\n",
        "\n",
        "_ = train_full_model(\n",
        "    model=model_2,\n",
        "    train_iterator=train_dataloader,\n",
        "    valid_iterator=valid_dataloader,\n",
        "    optimizer=optimizer_2,\n",
        "    criterion=criterion,\n",
        "    n_epochs=N_EPOCHS,\n",
        "    clip=CLIP,\n",
        "    model_save_path=MODEL_SAVE_PATH_2,\n",
        "    model_name=\"Model 2 (Luong)\"\n",
        ")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"\\n  Model 2 (Luong-GRU)  training completed\")\n",
        "print(f\"  Best Model 2 saved: '{MODEL_SAVE_PATH_2}'\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4223fda5",
      "metadata": {},
      "source": [
        "## Scaled Dot-Product Attention\n",
        "Implements scaled dot-product attention with 1/sqrt(d_k) scaling factor to prevent softmax saturation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4708c823-7c62-4471-85a6-756a365a3a95",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4708c823-7c62-4471-85a6-756a365a3a95",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "4b627eca-4e02-4326-aac9-c5f526cb39fb"
      },
      "outputs": [],
      "source": [
        "class AttentionScaledDotProduct(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # Same as Luong but with scaling factor\n",
        "        self.attn_in = nn.Linear(enc_hid_dim, dec_hid_dim)\n",
        "        self.hid_dim = dec_hid_dim  # Store for scaling\n",
        "\n",
        "    def forward(self, decoder_hidden, encoder_outputs):\n",
        "\n",
        "        # decoder_hidden  = [batch_size, dec_hid_dim]\n",
        "        # encoder_outputs = [src_len, batch_size, enc_hid_dim]\n",
        "\n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        # Step 1: Project encoder outputs\n",
        "        encoder_proj = self.attn_in(encoder_outputs)  # [src_len, B, dec_hid]\n",
        "\n",
        "        # Step 2: Prepare for batch matrix multiplication\n",
        "        decoder_hidden_unsqueezed = decoder_hidden.unsqueeze(1)  # [B, 1, H]\n",
        "        encoder_proj_permuted = encoder_proj.permute(1, 0, 2)    # [B, S, H]\n",
        "        encoder_proj_t = encoder_proj_permuted.permute(0, 2, 1)  # [B, H, S]\n",
        "\n",
        "        # Step 3: Multiplicative scoring\n",
        "        energy_unsqueezed = torch.bmm(decoder_hidden_unsqueezed, encoder_proj_t)  # [B, 1, S]\n",
        "\n",
        "        # Step 4: Apply scaling (key difference from Luong)\n",
        "        scale = self.hid_dim ** 0.5  # sqrt(d_k)\n",
        "        energy_scaled = energy_unsqueezed / scale\n",
        "        energy = energy_scaled.squeeze(1)  # [B, S]\n",
        "\n",
        "        # Step 5: Apply softmax\n",
        "        return F.softmax(energy, dim=1)\n",
        "\n",
        "print(\"  Attention (Scaled Dot-Product) defined\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe895573",
      "metadata": {},
      "source": [
        "## Model 3 Training (Scaled Dot-Product)\n",
        "Initializes and trains Model 3 with scaled dot-product attention mechanism."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eafc5bdc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eafc5bdc",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "15e8782b-ed0e-4244-fe43-b0dacc269a83"
      },
      "outputs": [],
      "source": [
        "# Build Model 3 architecture\n",
        "\n",
        "# Create encoder (same architecture, new instance)\n",
        "encoder_3 = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT).to(device)\n",
        "\n",
        "# Create new attention mechanism (Scaled Dot-Product)\n",
        "attention_3 = AttentionScaledDotProduct(ENC_HID_DIM_CALC, DEC_HID_DIM_CALC).to(device)\n",
        "\n",
        "# Create decoder with new attention\n",
        "decoder_3 = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM_CALC, DEC_HID_DIM_CALC,\n",
        "                    DEC_DROPOUT, N_LAYERS, attention_3).to(device)\n",
        "\n",
        "# Create Model 3: Scaled-Dot-Product-Attention-GRU\n",
        "model_3 = Seq2Seq(encoder_3, decoder_3, device, PAD_IDX).to(device)\n",
        "\n",
        "# Initialize weights\n",
        "model_3.apply(init_weights)\n",
        "\n",
        "print(f\"  Model 3 (Scaled Dot-Product-GRU) initialized: {count_parameters(model_3):,} parameters\")\n",
        "\n",
        "# Setup optimizer for Model 3\n",
        "optimizer_3 = optim.Adam(model_3.parameters(), lr=LEARNING_RATE)\n",
        "print(f\"  Model 3 Optimizer: Adam (LR={LEARNING_RATE})\")\n",
        "# Training configuration\n",
        "\n",
        "MODEL_SAVE_PATH_3 = 'model-3-scaled-dot-gru.pt'\n",
        "\n",
        "best_valid_loss_3 = float('inf')\n",
        "\n",
        "print(f\"\\nTraining Model 3 (Scaled Dot-Product-GRU) for {N_EPOCHS} epochs...\")\n",
        "\n",
        "_ = train_full_model(\n",
        "    model=model_3,\n",
        "    train_iterator=train_dataloader,\n",
        "    valid_iterator=valid_dataloader,\n",
        "    optimizer=optimizer_3,\n",
        "    criterion=criterion,\n",
        "    n_epochs=N_EPOCHS,\n",
        "    clip=CLIP,\n",
        "    model_save_path=MODEL_SAVE_PATH_3,\n",
        "    model_name=\"Model 3 (Scaled Dot)\"\n",
        ")\n",
        "\n",
        "print(f\"\\n  Model 3 (Scaled Dot-Product-GRU) training completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70d50612",
      "metadata": {},
      "source": [
        "## Translation and Metrics Utilities\n",
        "Defines translate_sentence for greedy decoding and calculate_metrics for BLEU-4/ROUGE-L evaluation using torchmetrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3a46d66-1ca3-41b7-88ba-ebd733bdddf3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "c3a46d66-1ca3-41b7-88ba-ebd733bdddf3",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "141e2413-e205-411c-843a-c458f5662394"
      },
      "outputs": [],
      "source": [
        "%pip install torchmetrics -q\n",
        "from torchmetrics.text import BLEUScore, ROUGEScore\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"\\n  torchmetrics library verified\")\n",
        "\n",
        "\n",
        "def translate_sentence(model, src_tokens, max_len=50):\n",
        "    \"\"\"\n",
        "    Translate a single sentence and return attention weights.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Convert tokens to indices\n",
        "    src_indices = [src_vocab.get(t, UNK_IDX) for t in src_tokens]\n",
        "    src_indices = [SOS_IDX] + src_indices + [EOS_IDX]\n",
        "    src_tensor = torch.tensor(src_indices, dtype=torch.long, device=device).unsqueeze(1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Encode source\n",
        "        encoder_outputs, encoder_hidden = model.encoder(src_tensor)\n",
        "\n",
        "        # Bridge: encoder hidden -> decoder hidden\n",
        "        n_layers = model.encoder.n_layers\n",
        "        batch_size = encoder_hidden.shape[1]\n",
        "        hid_dim = model.encoder.hid_dim\n",
        "\n",
        "        # 1. View: Separate layers and directions\n",
        "        encoder_hidden = encoder_hidden.view(n_layers, 2, batch_size, hid_dim)\n",
        "\n",
        "        # 2. Cat: Combine forward and backward Hidden states\n",
        "        encoder_hidden_cat = torch.cat((encoder_hidden[:, 0, :, :], encoder_hidden[:, 1, :, :]), dim=2)\n",
        "        decoder_hidden = torch.tanh(model.fc_hidden(encoder_hidden_cat))\n",
        "\n",
        "    # Greedy decoding\n",
        "    trg_indices = [SOS_IDX]\n",
        "    input_token = torch.tensor([SOS_IDX], dtype=torch.long, device=device)\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        prediction, decoder_hidden, attn_weights = model.decoder(\n",
        "            input_token, decoder_hidden, encoder_outputs\n",
        "        )\n",
        "        top1_index = prediction.argmax(1)\n",
        "        trg_indices.append(top1_index.item())\n",
        "\n",
        "        if top1_index.item() == EOS_IDX:\n",
        "            break\n",
        "        input_token = top1_index\n",
        "\n",
        "    # Convert indices to tokens\n",
        "    trg_tokens = [trg_itos[idx] for idx in trg_indices[1:] if idx != EOS_IDX]\n",
        "    return trg_tokens, attn_weights\n",
        "\n",
        "\n",
        "def calculate_metrics(dataset, model):\n",
        "    \"\"\"\n",
        "    Calculate BLEU-4 and ROUGE-L scores on dataset.\n",
        "    \"\"\"\n",
        "    bleu_metric = BLEUScore(n_gram=4)\n",
        "    rouge_metric = ROUGEScore(rouge_keys=(\"rougeLsum\",))\n",
        "\n",
        "    hyp_lists = []   # List[str] - BLEU expects strings\n",
        "    ref_lists = []   # List[List[str]]\n",
        "\n",
        "    print(f\"  Translating (N={len(dataset)})...\")\n",
        "\n",
        "    for example in tqdm(dataset, desc=\"Translating\", leave=False):\n",
        "        src_tokens = example[\"src_tokens\"]\n",
        "        trg_tokens = example[\"trg_tokens\"]\n",
        "\n",
        "        # Generate translation\n",
        "        hyp_tokens, _ = translate_sentence(model, src_tokens)\n",
        "\n",
        "        # Clean special tokens\n",
        "        hyp_tokens = [t for t in hyp_tokens if t not in [EOS_TOKEN, SOS_TOKEN, PAD_TOKEN]]\n",
        "        ref_tokens = [t for t in trg_tokens if t not in [EOS_TOKEN, SOS_TOKEN, PAD_TOKEN]]\n",
        "\n",
        "        # Convert to strings for BLEU\n",
        "        hyp_lists.append(\" \".join(hyp_tokens))\n",
        "        ref_lists.append([\" \".join(ref_tokens)])\n",
        "\n",
        "    # Calculate BLEU (expects string inputs)\n",
        "    bleu_score = bleu_metric(hyp_lists, ref_lists)\n",
        "\n",
        "    # Calculate ROUGE (also expects strings)\n",
        "    rouge_score = rouge_metric(hyp_lists, [r[0] for r in ref_lists])\n",
        "\n",
        "    return bleu_score.item(), rouge_score[\"rougeLsum_fmeasure\"].item()\n",
        "\n",
        "\n",
        "def debug_some_translations(model, n_samples=5):\n",
        "    \"\"\"Display sample translations for qualitative analysis.\"\"\"\n",
        "    for i in range(n_samples):\n",
        "        ex = tokenized_datasets[\"test\"][i]\n",
        "        src_tokens = ex[\"src_tokens\"]\n",
        "        trg_tokens = ex[\"trg_tokens\"]\n",
        "        hyp_tokens, _ = translate_sentence(model, src_tokens)\n",
        "\n",
        "        print(f\"\\n=== Sample {i} ===\")\n",
        "        print(\"SRC:\", \" \".join(src_tokens))\n",
        "        print(\"TRG:\", \" \".join(trg_tokens))\n",
        "        print(\"HYP:\", \" \".join(hyp_tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d46b1fc7",
      "metadata": {},
      "source": [
        "## Final Test Evaluation\n",
        "Loads all three trained models and evaluates them on test set with Loss, Perplexity, BLEU-4, and ROUGE-L metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a99c278-98b3-4aad-a3d5-f686f84995c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1a99c278-98b3-4aad-a3d5-f686f84995c7",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "d836130a-b9be-4692-ebb6-5b80bfa08025"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "import torch\n",
        "\n",
        "# ======================================================================\n",
        "# FINAL TEST EVALUATION - ALL ATTENTION MECHANISMS\n",
        "# ======================================================================\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"FINAL TEST EVALUATION - ALL ATTENTION MECHANISMS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Helper function to load models dynamically\n",
        "def load_checkpoint_model(attn_type, path, attn_dim=None):\n",
        "    \"\"\"\n",
        "    Belirtilen attention tipine gre modeli oluturur ve arlklar ykler.\n",
        "    \"\"\"\n",
        "    # Encoder always same\n",
        "    enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT).to(device)\n",
        "\n",
        "    # Attention selection\n",
        "    if attn_type == 'bahdanau':\n",
        "        attn = Attention(ENC_HID_DIM_CALC, DEC_HID_DIM_CALC, attn_dim).to(device)\n",
        "    elif attn_type == 'luong':\n",
        "        attn = AttentionLuong(ENC_HID_DIM_CALC, DEC_HID_DIM_CALC).to(device)\n",
        "    elif attn_type == 'scaled':\n",
        "        attn = AttentionScaledDotProduct(ENC_HID_DIM_CALC, DEC_HID_DIM_CALC).to(device)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown attention type\")\n",
        "\n",
        "    # Create decoder\n",
        "    dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM_CALC, DEC_HID_DIM_CALC,\n",
        "                  DEC_DROPOUT, N_LAYERS, attn).to(device)\n",
        "\n",
        "    # Combine into Seq2Seq model\n",
        "    model = Seq2Seq(enc, dec, device, PAD_IDX).to(device)\n",
        "\n",
        "    # Load weights\n",
        "    model.load_state_dict(torch.load(path, map_location=device))\n",
        "    return model\n",
        "\n",
        "# 1. Load Models\n",
        "print(\"\\nLoading models...\")\n",
        "try:\n",
        "    model_1_eval = load_checkpoint_model('bahdanau', 'model-1-bahdanau-gru.pt', ATTN_DIM)\n",
        "    print(\"  Model 1 (Bahdanau) loaded.\")\n",
        "\n",
        "    model_2_eval = load_checkpoint_model('luong', 'model-2-luong-gru.pt')\n",
        "    print(\"  Model 2 (Luong) loaded.\")\n",
        "\n",
        "    model_3_eval = load_checkpoint_model('scaled', 'model-3-scaled-dot-gru.pt')\n",
        "    print(\"  Model 3 (Scaled Dot-Product) loaded\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"\\nERROR: Model dosyas bulunamad! Ltfen eitimi tamamladnzdan emin olun.\\nDetay: {e}\")\n",
        "\n",
        "# 2. Loss and Perplexity Evaluation\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"TEST SET LOSS AND PERPLEXITY EVALUATION\")\n",
        "print(\"=\" * 70, flush=True)\n",
        "\n",
        "test_loss_1 = evaluate(model_1_eval, test_dataloader, criterion)\n",
        "test_ppl_1 = math.exp(test_loss_1)\n",
        "print(f\"\\n[Model 1 - Bahdanau] Test Loss: {test_loss_1:.3f} | Test PPL: {test_ppl_1:7.3f}\", flush=True)\n",
        "\n",
        "test_loss_2 = evaluate(model_2_eval, test_dataloader, criterion)\n",
        "test_ppl_2 = math.exp(test_loss_2)\n",
        "print(f\"[Model 2 - Luong]    Test Loss: {test_loss_2:.3f} | Test PPL: {test_ppl_2:7.3f}\", flush=True)\n",
        "\n",
        "test_loss_3 = evaluate(model_3_eval, test_dataloader, criterion)\n",
        "test_ppl_3 = math.exp(test_loss_3)\n",
        "print(f\"[Model 3 - Scaled]   Test Loss: {test_loss_3:.3f} | Test PPL: {test_ppl_3:7.3f}\", flush=True)\n",
        "\n",
        "# 3. BLEU and ROUGE Evaluation\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"TEST SET BLEU AND ROUGE EVALUATION\")\n",
        "print(\"=\" * 70, flush=True)\n",
        "\n",
        "\n",
        "print(\"\\n[Model 1 - Bahdanau] calculating...\", flush=True)\n",
        "bleu_1, rouge_1 = calculate_metrics(tokenized_datasets['test'], model_1_eval)\n",
        "print(f\"  BLEU-4: {bleu_1:.4f} | ROUGE-L: {rouge_1:.4f}\", flush=True)\n",
        "\n",
        "print(\"\\n[Model 2 - Luong] calculating...\", flush=True)\n",
        "bleu_2, rouge_2 = calculate_metrics(tokenized_datasets['test'], model_2_eval)\n",
        "print(f\"  BLEU-4: {bleu_2:.4f} | ROUGE-L: {rouge_2:.4f}\", flush=True)\n",
        "\n",
        "print(\"\\n[Model 3 - Scaled Dot-Product] calculating...\", flush=True)\n",
        "bleu_3, rouge_3 = calculate_metrics(tokenized_datasets['test'], model_3_eval)\n",
        "print(f\"  BLEU-4: {bleu_3:.4f} | ROUGE-L: {rouge_3:.4f}\", flush=True)\n",
        "\n",
        "# 4. Summary Table\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"COMPARATIVE SUMMARY TABLE\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"{'Model':<25} {'Test Loss':<12} {'Test PPL':<12} {'BLEU-4':<12} {'ROUGE-L':<12}\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'1. Bahdanau (Additive)':<25} {test_loss_1:<12.3f} {test_ppl_1:<12.3f} {bleu_1:<12.4f} {rouge_1:<12.4f}\")\n",
        "print(f\"{'2. Luong (Multiplicative)':<25} {test_loss_2:<12.3f} {test_ppl_2:<12.3f} {bleu_2:<12.4f} {rouge_2:<12.4f}\")\n",
        "print(f\"{'3. Scaled Dot-Product':<25} {test_loss_3:<12.3f} {test_ppl_3:<12.3f} {bleu_3:<12.4f} {rouge_3:<12.4f}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# 5. Save results as JSON\n",
        "results_dict = {\n",
        "    'Bahdanau': {'test_loss': test_loss_1, 'test_ppl': test_ppl_1, 'bleu': bleu_1, 'rouge': rouge_1},\n",
        "    'Luong': {'test_loss': test_loss_2, 'test_ppl': test_ppl_2, 'bleu': bleu_2, 'rouge': rouge_2},\n",
        "    'Scaled': {'test_loss': test_loss_3, 'test_ppl': test_ppl_3, 'bleu': bleu_3, 'rouge': rouge_3}\n",
        "}\n",
        "\n",
        "with open('attention_comparison_results.json', 'w') as f:\n",
        "    json.dump(results_dict, f, indent=4)\n",
        "print(\"\\n  Results saved to 'attention_comparison_results.json'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d915537",
      "metadata": {},
      "source": [
        "## Attention Visualization and Entropy Analysis\n",
        "Generates attention heatmaps for 5 test samples and calculates entropy to measure attention sharpness across models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99cd3ce4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "99cd3ce4",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "eaedcefd-3355-4caf-c0c0-cc91c6c151fa"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"QUALITATIVE ANALYSIS: VISUALIZATION AND ENTROPY ANALYSIS ON 5 SAMPLES\")\n",
        "print(\"=\" * 70)\n",
        "#Helper function to calculate attention entropy\n",
        "def calculate_attention_entropy(attention_matrix):\n",
        "    \"\"\"\n",
        "    Calculate average entropy of attention distributions across all decoder time steps.\n",
        "    Lower entropy indicates sharper attention.\n",
        "    \"\"\"\n",
        "    # Attention_matrix: numpy array of shape (trg_len, src_len)\n",
        "    row_entropies = []\n",
        "    for row in attention_matrix:\n",
        "        row = np.array(row) + 1e-9\n",
        "        row = row / row.sum()\n",
        "        ent = entropy(row)\n",
        "        row_entropies.append(ent)\n",
        "\n",
        "    return np.mean(row_entropies)\n",
        "\n",
        "\n",
        "def visualize_attention(model, model_name, src_tokens, trg_tokens, sample_id, max_trg_len=20):\n",
        "    model.eval()\n",
        "\n",
        "    src_indices = [src_vocab.get(token, UNK_IDX) for token in src_tokens]\n",
        "    src_indices = [SOS_IDX] + src_indices + [EOS_IDX]\n",
        "    src_tensor = torch.tensor(src_indices, dtype=torch.long, device=device).unsqueeze(1)\n",
        "    \n",
        "    \n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, encoder_hidden = model.encoder(src_tensor)\n",
        "        \n",
        "        # Bridge: encoder hidden -> decoder hidden (translate_sentence ile ayn)\n",
        "        n_layers = model.encoder.n_layers\n",
        "        batch_size = encoder_hidden.shape[1]\n",
        "        hid_dim = model.encoder.hid_dim\n",
        "        \n",
        "        # 1. View: Separate layers and directions\n",
        "        encoder_hidden = encoder_hidden.view(n_layers, 2, batch_size, hid_dim)\n",
        "        \n",
        "        # 2. Cat: Combine forward and backward hidden states\n",
        "        encoder_hidden_cat = torch.cat((encoder_hidden[:, 0, :, :], encoder_hidden[:, 1, :, :]), dim=2)\n",
        "        decoder_hidden = torch.tanh(model.fc_hidden(encoder_hidden_cat))\n",
        "\n",
        "    trg_indices = [SOS_IDX]\n",
        "    input_token = torch.tensor([SOS_IDX], dtype=torch.long, device=device)\n",
        "    attention_weights_list = []\n",
        "\n",
        "    for _ in range(max_trg_len):\n",
        "        prediction, decoder_hidden, attn_weights = model.decoder(input_token, decoder_hidden, encoder_outputs)\n",
        "        attention_weights_list.append(attn_weights.detach().cpu().squeeze(0).numpy())\n",
        "        top1_index = prediction.argmax(1)\n",
        "        trg_indices.append(top1_index.item())\n",
        "        if top1_index.item() == EOS_IDX: break\n",
        "        input_token = top1_index\n",
        "\n",
        "    attention_matrix = np.array(attention_weights_list)\n",
        "\n",
        "    avg_entropy = calculate_attention_entropy(attention_matrix)\n",
        "\n",
        "    #Visualization\n",
        "    src_display = ['<sos>'] + src_tokens + ['<eos>']\n",
        "    trg_display = [trg_itos[idx] for idx in trg_indices[1:]] # <sos> hari\n",
        "\n",
        "    # Heatmap\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(attention_matrix,\n",
        "                xticklabels=src_display,\n",
        "                yticklabels=trg_display,\n",
        "                cmap='viridis', cbar_kws={'label': 'Attention Weight'})\n",
        "\n",
        "    plt.xlabel('Source (German)')\n",
        "    plt.ylabel('Target (English)')\n",
        "    plt.title(f'{model_name} (Sample {sample_id})\\nAvg Entropy: {avg_entropy:.4f} (Lower is Sharper)',\n",
        "              fontsize=14, fontweight='bold')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Dosya ismine sample id ekle (stne yazmasn)\n",
        "    filename = f'attn_{model_name.split()[0].lower()}_sample{sample_id}.png'\n",
        "    plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    return avg_entropy\n",
        "\n",
        "# (Task 2c) ---\n",
        "models_for_viz = {\n",
        "    'Bahdanau': model_1_eval,\n",
        "    'Luong': model_2_eval,\n",
        "    'Scaled': model_3_eval\n",
        "}\n",
        "\n",
        "entropy_results = {'Bahdanau': [], 'Luong': [], 'Scaled': []}\n",
        "\n",
        "# lk 5 rnei se\n",
        "for i in range(5):\n",
        "    example = tokenized_datasets['test'][i]\n",
        "    src = example['src_tokens']\n",
        "    trg = example['trg_tokens']\n",
        "\n",
        "    print(f\"\\n--- SAMPLE {i+1} ANALYSIS ---\")\n",
        "    print(f\"DE: {' '.join(src)}\")\n",
        "    print(f\"EN: {' '.join(trg)}\")\n",
        "\n",
        "    for name, model in models_for_viz.items():\n",
        "        ent = visualize_attention(model, name, src, trg, sample_id=i+1)\n",
        "        entropy_results[name].append(ent)\n",
        "\n",
        "# --- ENTROP ZET (Task 2e) ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"AVERAGE ENTROPY (SHARPNESS) ANALYSIS\")\n",
        "print(\"=\"*50)\n",
        "for name, entropies in entropy_results.items():\n",
        "    avg_ent = np.mean(entropies)\n",
        "    sharpness = \"High\" if avg_ent < 1.5 else \"Low\"\n",
        "    print(f\"{name:<10} | Avg Entropy: {avg_ent:.4f} | Sharpness: {sharpness}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c9438cb",
      "metadata": {},
      "source": [
        "## Entropy-Performance Correlation\n",
        "Analyzes Pearson correlation between attention entropy and performance metrics (BLEU, ROUGE, Perplexity)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aff926d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aff926d3",
        "outputId": "c0b3ea22-0bd0-4419-f4d9-61cd800e6dac"
      },
      "outputs": [],
      "source": [
        "# Task (e): Analyze correlation between attention entropy and performance metrics\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Calculate average entropy per model (across 5 samples)\n",
        "entropies = [np.mean(entropy_results['Bahdanau']),\n",
        "             np.mean(entropy_results['Luong']),\n",
        "             np.mean(entropy_results['Scaled'])]\n",
        "\n",
        "# Collect performance metrics (from previous evaluation)\n",
        "bleu_scores = [bleu_1, bleu_2, bleu_3]\n",
        "rouge_scores = [rouge_1, rouge_2, rouge_3]\n",
        "ppl_scores = [test_ppl_1, test_ppl_2, test_ppl_3]\n",
        "\n",
        "# Compute Pearson correlation: Does sharper attention correlate with better performance?\n",
        "corr_bleu, p_bleu = pearsonr(entropies, bleu_scores)\n",
        "corr_rouge, p_rouge = pearsonr(entropies, rouge_scores)\n",
        "corr_ppl, p_ppl = pearsonr(entropies, ppl_scores)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ENTROPY-PERFORMANCE CORRELATION ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n{'Metric':<15} {'Correlation':<15} {'p-value':<10} {'Interpretation'}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'BLEU':<15} {corr_bleu:+.3f}          {p_bleu:.3f}      \", end=\"\")\n",
        "print(\"Sharp attention better\" if corr_bleu < 0 else \"Diffuse attention better\")\n",
        "print(f\"{'ROUGE':<15} {corr_rouge:+.3f}          {p_rouge:.3f}      \", end=\"\")\n",
        "print(\"Sharp attention better\" if corr_rouge < 0 else \"Diffuse attention better\")\n",
        "print(f\"{'Perplexity':<15} {corr_ppl:+.3f}          {p_ppl:.3f}      \", end=\"\")\n",
        "print(\"Sharp attention better\" if corr_ppl > 0 else \"Diffuse attention better\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FULL COMPARISON\")\n",
        "print(\"=\" * 60)\n",
        "models = ['Bahdanau', 'Luong', 'Scaled']\n",
        "print(f\"{'Model':<12} {'BLEU':<8} {'ROUGE':<8} {'PPL':<8} {'Entropy':<10}\")\n",
        "print(\"-\" * 60)\n",
        "for i, name in enumerate(models):\n",
        "    print(f\"{name:<12} {bleu_scores[i]:.4f}   {rouge_scores[i]:.4f}   \"\n",
        "          f\"{ppl_scores[i]:.2f}   {entropies[i]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe4c7a66",
      "metadata": {},
      "source": [
        "## Correlation Scatter Plots\n",
        "Visualizes entropy vs performance metrics with scatter plots showing correlation coefficients for each model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01a15319",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "01a15319",
        "outputId": "8dd9af40-94d2-43ab-9f26-baf95e47811f"
      },
      "outputs": [],
      "source": [
        "# Visualize entropy-performance correlations with scatter plots\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']  # Distinct color per model\n",
        "\n",
        "# Plot 1: BLEU vs Entropy\n",
        "axes[0].scatter(entropies, bleu_scores, s=150, c=colors, edgecolors='black', linewidths=2)\n",
        "for i, name in enumerate(models):\n",
        "    axes[0].annotate(name, (entropies[i], bleu_scores[i]), fontsize=10, ha='center', va='bottom')\n",
        "axes[0].set_xlabel('Entropy')\n",
        "axes[0].set_ylabel('BLEU')\n",
        "axes[0].set_title(f'BLEU vs Entropy (={corr_bleu:.3f})')\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "axes[1].scatter(entropies, rouge_scores, s=150, c=colors, edgecolors='black', linewidths=2)\n",
        "for i, name in enumerate(models):\n",
        "    axes[1].annotate(name, (entropies[i], rouge_scores[i]), fontsize=10, ha='center', va='bottom')\n",
        "axes[1].set_xlabel('Entropi')\n",
        "axes[1].set_ylabel('ROUGE')\n",
        "axes[1].set_title(f'ROUGE vs Entropi (={corr_rouge:.3f})')\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "axes[2].scatter(entropies, ppl_scores, s=150, c=colors, edgecolors='black', linewidths=2)\n",
        "for i, name in enumerate(models):\n",
        "    axes[2].annotate(name, (entropies[i], ppl_scores[i]), fontsize=10, ha='center', va='bottom')\n",
        "axes[2].set_xlabel('Entropi')\n",
        "axes[2].set_ylabel('Perplexity')\n",
        "axes[2].set_title(f'PPL vs Entropi (={corr_ppl:.3f})')\n",
        "axes[2].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('entropy_performance_correlation.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n  Task (e) completed: Entropy-performance correlation analyzed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb392008",
      "metadata": {},
      "source": [
        "## Performance Comparison Visualization\n",
        "Creates bar charts and radar chart for comprehensive visual comparison of all attention mechanisms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b0533a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "1b0533a8",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "cae50fd4-f109-4e1d-8a78-fd5f0c9c5ff9"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"PERFORMANCE METRICS VISUAL COMPARISON\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Prepare data for visualization\n",
        "models_names = ['Bahdanau\\n(Additive)', 'Luong\\n(Multiplicative)', 'Scaled\\nDot-Product']\n",
        "test_losses = [test_loss_1, test_loss_2, test_loss_3]\n",
        "test_ppls = [test_ppl_1, test_ppl_2, test_ppl_3]\n",
        "\n",
        "# Create 2x2 grid of bar charts comparing all metrics\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "fig.suptitle('Attention Mechanisms Performance Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Chart 1: Test Loss (lower is better)\n",
        "axes[0, 0].bar(models_names, test_losses, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
        "axes[0, 0].set_ylabel('Test Loss', fontsize=11)\n",
        "axes[0, 0].set_title('Test Loss Comparison', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].grid(axis='y', alpha=0.3)\n",
        "for i, v in enumerate(test_losses):\n",
        "    axes[0, 0].text(i, v + 0.05, f'{v:.3f}', ha='center', fontsize=10)\n",
        "\n",
        "# Test Perplexity comparison\n",
        "axes[0, 1].bar(models_names, test_ppls, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
        "axes[0, 1].set_ylabel('Test Perplexity', fontsize=11)\n",
        "axes[0, 1].set_title('Test Perplexity Comparison', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].grid(axis='y', alpha=0.3)\n",
        "for i, v in enumerate(test_ppls):\n",
        "    axes[0, 1].text(i, v + 1, f'{v:.2f}', ha='center', fontsize=10)\n",
        "\n",
        "# BLEU-4 comparison\n",
        "axes[1, 0].bar(models_names, bleu_scores, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
        "axes[1, 0].set_ylabel('BLEU-4 Score', fontsize=11)\n",
        "axes[1, 0].set_title('BLEU-4 Score Comparison', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].grid(axis='y', alpha=0.3)\n",
        "for i, v in enumerate(bleu_scores):\n",
        "    axes[1, 0].text(i, v + 0.005, f'{v:.4f}', ha='center', fontsize=10)\n",
        "\n",
        "# ROUGE-L comparison\n",
        "axes[1, 1].bar(models_names, rouge_scores, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
        "axes[1, 1].set_ylabel('ROUGE-L Score', fontsize=11)\n",
        "axes[1, 1].set_title('ROUGE-L Score Comparison', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].grid(axis='y', alpha=0.3)\n",
        "for i, v in enumerate(rouge_scores):\n",
        "    axes[1, 1].text(i, v + 0.005, f'{v:.4f}', ha='center', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('attention_mechanisms_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n  Performance comparison chart saved as 'attention_mechanisms_comparison.png'\")\n",
        "\n",
        "# Create radar chart for holistic comparison across all metrics\n",
        "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
        "\n",
        "# Normalize all metrics to [0,1] range for fair comparison\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Prepare metrics matrix (invert loss/perplexity since lower is better)\n",
        "metrics_matrix = np.array([\n",
        "    [1 - (l / max(test_losses)) for l in test_losses],  # Normalized inverted loss\n",
        "    [1 - (p / max(test_ppls)) for p in test_ppls],      # Normalized inverted perplexity\n",
        "    bleu_scores,  # Higher is better (no inversion needed)\n",
        "    rouge_scores  # Higher is better (no inversion needed)\n",
        "])\n",
        "\n",
        "# Define radar chart axes\n",
        "categories = ['Loss\\n(lower better)', 'Perplexity\\n(lower better)', 'BLEU-4\\n(higher better)', 'ROUGE-L\\n(higher better)']\n",
        "N = len(categories)\n",
        "\n",
        "# Calculate angles for radar chart (divide circle into N equal parts)\n",
        "angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
        "angles += angles[:1]  # Close the circle\n",
        "\n",
        "# Plot each model as separate line on radar chart\n",
        "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
        "model_labels = ['Bahdanau', 'Luong', 'Scaled']\n",
        "\n",
        "for idx, (color, label) in enumerate(zip(colors, model_labels)):\n",
        "    values = metrics_matrix[:, idx].tolist()\n",
        "    values += values[:1]\n",
        "    ax.plot(angles, values, 'o-', linewidth=2, label=label, color=color)\n",
        "    ax.fill(angles, values, alpha=0.15, color=color)\n",
        "\n",
        "ax.set_xticks(angles[:-1])\n",
        "ax.set_xticklabels(categories, size=11)\n",
        "ax.set_ylim(0, 1)\n",
        "ax.set_title('Attention Mechanisms - Comprehensive Comparison', size=14, fontweight='bold', pad=20)\n",
        "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
        "ax.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('attention_mechanisms_radar.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"  Radar comparison chart saved as 'attention_mechanisms_radar.png'\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0596fd1400e7494a980f6276305d0b23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a1040eb409a4cc8af8aa7d23e72570c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "122df9973ad94b788c40be2ee17507ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2357faf8224d441d9965e1f30a0d4e41",
            "placeholder": "",
            "style": "IPY_MODEL_fd21256649d049fe9aabffcadf7a9473",
            "value": "29000/29000[00:07&lt;00:00,4103.49examples/s]"
          }
        },
        "147a36f534134f24a986a725bda8bd7c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2357faf8224d441d9965e1f30a0d4e41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38ec759f3b2e471487a8e8654bff9e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d43a49d9eb349f9856d6a9d8edf95e5",
              "IPY_MODEL_80dd0600bba946edbf3a4d32a1047bd0",
              "IPY_MODEL_66cdf8dd440b4e54a5b7dd2166a6dee5"
            ],
            "layout": "IPY_MODEL_0596fd1400e7494a980f6276305d0b23"
          }
        },
        "3eb2a3e890d8409d8053cf6d00a13b67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "453540ce326746b5a9e33e3069f9b364": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c04de4e32294f66884a11df95fc30bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70bc34df64b3480285bd61a95c8bcf3d",
            "placeholder": "",
            "style": "IPY_MODEL_5c5afd74794d4e43821660a0299f17dc",
            "value": "1000/1000[00:00&lt;00:00,5090.56examples/s]"
          }
        },
        "5039750a58474787b399e781ba8627ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53e5062051cb435481f8a81da1a484ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "544123e4bab845eb8740723748936de0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c5afd74794d4e43821660a0299f17dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d43a49d9eb349f9856d6a9d8edf95e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bea940495ee7419a98c1357dfdc1dee9",
            "placeholder": "",
            "style": "IPY_MODEL_53e5062051cb435481f8a81da1a484ff",
            "value": "Map:100%"
          }
        },
        "64c0a13198c943308f5065722ea3ff08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66cdf8dd440b4e54a5b7dd2166a6dee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0b117b83d264bc8a1aa36576e9cbdc2",
            "placeholder": "",
            "style": "IPY_MODEL_453540ce326746b5a9e33e3069f9b364",
            "value": "1014/1014[00:00&lt;00:00,5086.88examples/s]"
          }
        },
        "689584c0263e4ca28a99cd78f66cb0ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70bc34df64b3480285bd61a95c8bcf3d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80dd0600bba946edbf3a4d32a1047bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64c0a13198c943308f5065722ea3ff08",
            "max": 1014,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8875b0be938e4a1fab49ecc38cfbc793",
            "value": 1014
          }
        },
        "8875b0be938e4a1fab49ecc38cfbc793": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f9a86f8a3c24237814d249777327726": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb0663ae002544f59702e8498f2e34a5",
            "max": 29000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a091c10fa42346d7b59bc72676d5bb7d",
            "value": 29000
          }
        },
        "a091c10fa42346d7b59bc72676d5bb7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0b117b83d264bc8a1aa36576e9cbdc2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1658274fcb64747bf7bf12a686ce0ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8562c8af9444aa091ea083c893205c3",
              "IPY_MODEL_e2253d46aadd46588fe7c7005e0ba3b9",
              "IPY_MODEL_4c04de4e32294f66884a11df95fc30bf"
            ],
            "layout": "IPY_MODEL_544123e4bab845eb8740723748936de0"
          }
        },
        "a3004be1f35c40edb8b1c58dd73d093b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da56b3abef4145309af827c337358c16",
              "IPY_MODEL_9f9a86f8a3c24237814d249777327726",
              "IPY_MODEL_122df9973ad94b788c40be2ee17507ee"
            ],
            "layout": "IPY_MODEL_3eb2a3e890d8409d8053cf6d00a13b67"
          }
        },
        "a8562c8af9444aa091ea083c893205c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_147a36f534134f24a986a725bda8bd7c",
            "placeholder": "",
            "style": "IPY_MODEL_0a1040eb409a4cc8af8aa7d23e72570c",
            "value": "Map:100%"
          }
        },
        "aca8362e1ae24c1796f1b387eacd714f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be83520a9e1c4df7bb33397827b97a5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bea940495ee7419a98c1357dfdc1dee9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb0663ae002544f59702e8498f2e34a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da56b3abef4145309af827c337358c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aca8362e1ae24c1796f1b387eacd714f",
            "placeholder": "",
            "style": "IPY_MODEL_5039750a58474787b399e781ba8627ee",
            "value": "Map:100%"
          }
        },
        "e2253d46aadd46588fe7c7005e0ba3b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be83520a9e1c4df7bb33397827b97a5e",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_689584c0263e4ca28a99cd78f66cb0ba",
            "value": 1000
          }
        },
        "fd21256649d049fe9aabffcadf7a9473": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
